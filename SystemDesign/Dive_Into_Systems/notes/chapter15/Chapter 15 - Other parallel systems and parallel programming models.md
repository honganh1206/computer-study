What we focus on in this chapter:

1. Parallelism for hardware accelerators focusing on GPUs
2. General-purpose computing on GPUs (GPGPU computing) using CUDA
3. Distributed memory systems and message passing usign MPI
4. Cloud computing using MapReduce and Apache Spark

[[Flynn Taxonomy of Architecture]]

[[Hardware Acceleration and CUDA]]

[[Distributed Memory Systems]]

[[To Exascale and beyond]]

