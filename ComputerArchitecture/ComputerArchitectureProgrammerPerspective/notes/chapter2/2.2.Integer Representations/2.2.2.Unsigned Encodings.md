---
tags:
  - "#study"
  - "#review"
  - "#computer"
  - "#programming"
cssclasses:
  - center-images
---
We write a bit vector as either $\vec{x}$ to denote *the entire vector* or $[x_{w-1},x_{w-2},\dots,x_{0}]$ to denote *the individual bits of the vector*. 

When we treat $\vec{x}$ as a *number written in binary notation*, we obtain the *unsigned interpretation of $\vec{x}$*. In this encoding, each bit $x_{i}$ has value of 0 or 1. 

[[Contribution of bits in numeric value]]

[[Principle - Definition of unsigned encoding]]

[[Principle - Uniqueness of unsigned encoding]]

