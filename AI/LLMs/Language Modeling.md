Probability over sequences of tokens/words $p(x_{1},\dots,x_{L})$


```
P(the,mouse,ate,the,cheese) = 0.02
P(the,the,mouse,ate,the,chees) = 0.0001 # Syntactic knowledge, less probability
p(the,cheese,ate,the,mouse) = 0.001 # Semantic knowledge, less probability
```

LMs are generative models




